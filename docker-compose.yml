services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"   # make sure your frontend Dockerfile/nginx actually listens on 3000; otherwise change mapping (see notes)
    environment:
      # Use service DNS names for container-to-container calls
      - REACT_APP_SIGNALING_SERVER=http://signaling-server:3001
      - REACT_APP_INFERENCE_SERVER=http://inference-server:3002
    depends_on:
      - signaling-server
    networks:
      - webrtc-network
    restart: unless-stopped

  signaling-server:
    build:
      context: ./server
      dockerfile: Dockerfile.signaling
    ports:
      - "8080:3001"    # host:container (host 8080 -> container 3001)
    environment:
      - PORT=3001
      - NODE_ENV=development
    networks:
      - webrtc-network
    restart: unless-stopped
    healthcheck:
      # Use node inside the image to check /health (safer for node:alpine)
      test: ["CMD", "node", "-e", "const http=require('http'); http.get('http://localhost:3001/health', res=>{process.exit(res.statusCode===200?0:1)}).on('error',()=>process.exit(1));"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  inference-server:
    build:
      context: ./server
      dockerfile: Dockerfile.inference
    ports:
      - "3002:3002"
    environment:
      - PORT=3002
      - DEBUG=false
    volumes:
      - ./models:/app/models
    networks:
      - webrtc-network
    profiles:
      - server-mode
    restart: unless-stopped
    healthcheck:
      # This assumes the inference image has python and requests; if not, replace with a simple curl/wget or node check
      test: ["CMD-SHELL", "python -c \"import requests; print(requests.get('http://localhost:3002/health').status_code)\" || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

networks:
  webrtc-network:
    driver: bridge

volumes:
  models:
    driver: local
